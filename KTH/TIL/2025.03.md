# NLU 와 NLG

## NLU(Natural Language Understanding) | 자연어 이해

- NLU는 자연어 처리(NLP)의 하위 분야
- 컴퓨터 소프트웨어를 활용하여 음성이나 텍스트의 입력된 문장형태를 이해하는것

## NLG(Natural Language Generation)

- 컴퓨터가 자연어 텍스트를 생성하여 인간이 자연스럽게 소통하는 방식을 모방
- 인간과 유사한 텍스트나 음성 생성

## 자연어 처리의 어려움

- 문맥의 따른 모호성
- 표현의 중의성
- 규칙의 예외성

## 교착어, 굴절어, 고립어

- 교착어
  - 한국어,일본어,몽골어
    - 어간에 접사가 붙어 단어를 이루고 의미와 문법적 기능이 정해짐
- 굴절어
  - 라틴어,독일어,러시아어
    - 단어의 형태가 변하면서 문법적 기능이 변하는 언어
- 고립어
  - 영어,중국어
    - 단어의 형태가 변하지 않고 단어의 위치나 문맥으로 문법적 기능을 구분하는 언어

## 한국어에서 자연처리가 어려운 이유

- 교착어
  - 한국어는 교착어로 단어의 형태가 변하면서 문법적인 기능이 변하는 언어
    - ex) '나는' -> '나를' -> '나에게' -> '나로'
    - ex) '먹다' -> '먹는다' -> '먹었다' -> '먹으려면'
    - 타 언어에 비해 같은 단어라도 다양한 조합이 존재
- 단어 순서 및 주어생략
    - 한국어는 주어를 생략하는 경우가 많고 단어의 순서가 중요하지 않음
    - ex) '나는 밥을 먹었다' -> '밥을 먹었다' -> '먹었다'
    - ex) '나는 밥을 먹었다' -> '먹었다' -> '나는'
- 띄어쓰기
  - 한국어는 띄어쓰기가 제대로 지켜지지 않는 경우가 많음
    - ex) '나는 밥을 먹었다' -> '나는밥을먹었다'
    - ex) '나는 밥을 먹었다' -> '나는 밥을먹었다'
  - 정제단계 중 하나인 '분절' 단계에서 혼란 발생

## 언어학의 접근 방법

- 규칙기반 접근:
  - 언어학적 지식을 활용하여 문법적인 규칙을 만들어 자연어 처리
- 통계기반 접근:
  - 대량의 데이터를 활용하여 자연어 처리
  - 전자화된 텍스트(코퍼스)의 분석을 통해 얻어진 언어 단위의 분포와 빈도에 관한 정보 이용
- 신경망 기반 접근:
  - 인공신경망을 활용하여 자연어 처리

## 전통적인 자연언어 처리 파이프라인

1. Document
2. Pre-process
3. Tokenize, Sentence, Split
4. Part of speech tagger
5. Chunker
6. Class Matching
7. Querying
8. Post-process
9. Structured Data

## 음절, 형태소, 어절, 품사

- 음절
  - 하나의 덩어리로 여겨지는 최소 음운 단위
- 형태소
  - 의미를 가지는 최소 단위
  - 자립형태소, 의존형태소로 구분
- 어절
  - 띄어쓰기 단위
- 품사
  - 단어의 문법적 기능을 나타내는 분류
  - 품사를 분석해 구분하는 작업으 POS(Part of Speech) Tagging이라고 함
- 품사의 구분
  - 역할에 따라
    - 체언, 용언, 수식언, 관계언, 독립언
  - 의미에 따라
    - 명사, 대명사, 수사, 관형사, 부사,조사,감탄사,동사,형용사
  - 형태에 따라
    - 가변어, 불변어

## 형태론(morphology)

- 언어에서 의미를 갖는 가장 기본단위인 형태소를 분석
- 형태소 간의 상관관계를 규명하는 학문

## 형태소(morpheme)

- 의미를 가지는 최소 단위
- 의미 혹은 문법적 기능의 최소단위
# 형태소(Morpheme)

## 형태소의 종류

### 자립성 여부
- **자립 형태소**
  - 의미: 독립적으로 사용될 수 있는 형태소로, 문장에서 독자적인 의미를 가짐
  - 종류: 명사, 동사, 형용사, 부사, 감탄사
  - 예시: 나무, 먹다, 아름답다, 빨리, 아!

- **의존 형태소**
  - 의미: 독립적으로 사용될 수 없으며, 다른 형태소와 결합하여 의미를 형성함
  - 종류: 조사, 접사, 어미
  - 예시: -은, -이, -고, -었

### 의미적 분류
- **실질 형태소(어휘 형태소)**
  - 의미: 사물이나 개념을 직접 지칭하며, 실질적인 의미를 가짐
  - 종류: 명사, 동사, 형용사, 부사
  - 예시: 책, 달리다, 크다, 천천히

- **형식 형태소(문법 형태소)**
  - 의미: 문법적 관계를 나타내는 역할을 하며 독립적인 의미가 없음
  - 종류: 조사, 접사, 어미
  - 예시: -은, -이, -고, -었

---

## 형태와 이형태

- **형태(Form)**: 의미를 가지는 최소 단위로, 변하지 않는 기본 단위
- **이형태(Allomorph)**: 같은 의미를 가지지만 문법적 환경에 따라 형태가 변형되는 경우 (예: ‘-이’와 ‘-가’)

---

# 통사론(Syntax)

- 문장의 구조와 형식을 연구하는 언어학의 한 분야

## 구조적 모호성(Structural Ambiguity)

- 동일한 표층 구조가 여러 개의 심층 구조를 가질 수 있는 현상
  - 예: "나는 그녀의 사진을 좋아한다." (그녀가 찍힌 사진 vs. 그녀의 소유물)

## 반복(Recursion)

- 문법 규칙이 자기 자신을 호출할 수 있는 성질로, 무한한 문장 생성이 가능함
  - 예: "그는 그녀가 온 것을 몰랐다." → 문장 안에 문장이 중첩됨

## 구 구조규칙(Phrase Structure Rule)

- 문장의 기본 구조를 정의하는 규칙
  - 예: S → NP VP (문장은 명사구와 동사구로 구성됨)

## 어휘규칙(Lexical Rule)

- 특정한 어휘가 문장에서 어떻게 사용될 수 있는지를 기술하는 규칙

## 변형규칙(Transformation Rules)

- 문장의 구조를 변형시키는 규칙
  - 예: 능동태 → 수동태 변형 ("철수가 책을 읽었다." → "책이 철수에 의해 읽혔다.")

---

# 의미론(Semantics)

- **개념적 의미(Conceptual Meaning)**: 단어의 기본적인 의미 요소
- **연상적 의미(Associative Meaning)**: 개인적, 사회적 맥락에 따른 의미적 확장

## 의미자질(Semantic Features)

- 단어의 의미적 속성을 분석하여 의미를 구성하는 최소 단위로 구분
  - 예: ‘사람’ → [+생명체, +이성적 존재]

## 의미역(Semantic Roles)

- 문장에서 각 성분이 담당하는 의미적 역할
  - 예: 주체(Agent), 대상(Patient), 도구(Instrument), 장소(Location)

## 의미 관계(Semantic Relations)

- **상하관계(Hyponymy)**: 상위어와 하위어의 관계 (예: ‘과일’ - ‘사과’)
- **동음 이철어(Homophones)**: 동일한 발음을 가지지만 의미가 다른 단어 (예: 배(boat) vs. 배(stomach))
- **동음 이어의(Homonyms)**: 동일한 철자와 발음을 가지지만 의미가 완전히 다른 단어 (예: 밤(night) vs. 밤(chestnut))
- **다의어(Polysemy)**: 하나의 단어가 여러 관련된 의미를 가짐 (예: 손(hand) → 신체부위 vs. 도움)
- **연어(Collocation)**: 특정 단어들이 함께 자주 사용되는 패턴 (예: "높은 산", "깊은 바다")

---

# 화용론(Pragmatics)

- 문맥과 사회적 요인에 따라 의미가 어떻게 변화하는지를 연구하는 분야

---

# 자연언어처리(NLP)에서의 언어학

## 주요 분석 기법
- **토큰화(Tokenization)**: 텍스트를 의미 단위로 나누는 과정
- **품사 태깅(POS Tagging)**: 각 단어에 품사 정보를 부착
- **구문 분석(Syntax Parsing)**: 문장의 문법적 구조 분석
- **의미 분석(Semantic Analysis)**: 문장의 의미를 해석
- **개체명 인식(NER)**: 고유명사(사람, 장소, 조직 등) 식별
- **문법 교정(GEC)**: 문장의 문법 오류 수정
- **의존 구문 분석(Dependency Parsing)**: 단어 간의 종속 관계를 분석

## BERT와 언어 구조
- BERT는 문맥을 고려하여 단어 간 관계를 학습하며, 다층적인 의미 표현을 가능하게 함
- LIMIT-BERT: 기존 BERT 모델에 언어학적 지식을 추가하여 성능을 향상시킨 모델

---

# 전처리(Preprocessing)

## 주요 기법
- **HTML 태그, 특수문자, 이모티콘 제거**: 비언어적 요소 제거
- **정규표현식(Regular Expression)**: 패턴 기반 텍스트 정제
- **불용어(Stopword) 제거**: 자주 등장하지만 의미가 적은 단어 필터링
- **어간추출(Stemming) vs. 표제어 추출(Lemmatization)**:
  - 어간추출: 단어의 기본형을 찾기 위해 단순 변환 (예: ‘running’ → ‘run’)
  - 표제어 추출: 문맥을 고려하여 정확한 기본형을 반환 (예: ‘better’ → ‘good’)

## 주요 라이브러리
- **KoNLPy**: 한국어 형태소 분석 라이브러리
- **NLTK**: 영어 자연어 처리 도구

## 토큰화(Tokenization) 주의사항
- 하나의 단어가 다양한 의미를 가질 수 있음
- 문맥에 따라 다른 품사로 해석될 가능성이 존재함


# 3-1 텍스트 전처리란?
