# 2025-02-28

# TIL

-생성 모델: 필수적인 정보로부터 데이터 분포를 학습, 새로운 데이터를 생성

-고전 생성 모델: 확률 분포를 추정하고 근사한다.
● 가우시안 혼합 모델: 여러 개의 가우시안 분포(정규분포)를 조합하여 데이터를 모델링 하는 확률 기반 생성 모델.
데이터가 여러 개의 정규분포에서 생성되었다고 가정하고, 각 데이터가 어떤 정규분포에서 나왔는지 확률적으로 결정하는 모델.
● 제한된 볼츠만 머신: 볼츠만 분포, classification 같이 feature를 출력하는 것과 흡사하다.
● 심층 신뢰망(DBN): 볼츠만 머신 여러 층 이은거.
● 자기 회귀 기반의 생성 모델: 이전까지 생성한 것을 바탕으로 추정

-딥러닝 기반의 생성 모델
● 오토 인코더(VAE): 입력 데이터를 저차원으로 압축했다가 다시 원래 데이터로 복원하는 비지도 학습 신경망 모델. 시간이 갈수록, 분포 개선, 학습 개선, 벡터 양자화, 고성능, 고해상도로 발전해갔다.
● GANs: 판별기와 생성기, 두 신경망이 경쟁하면서 학습하는 모델. 생성기는 판별기를 속일 가짜 데이터를 만들고, 판별기는 생성기가 만든 가짜 데이터와 진짜 데이터를 판별하며 경쟁한다.
 시간이 갈수록, 더 높은 성능, 다양한 도메인으로 확장한다.
● 확산 모델(Diffusion Model): 확산(Forward)과 역산(Reverse)으로 이루어져있다. 시간이 갈수록, 생성 방식, 모델 개선, 다양한 도메인이 가능해지고 개인화 방법이 등장했다.




-판별 모델: 주어진 데이터를 통해 데이터 사이의 경계를 예측 (로지스틱 회귀, 분류)
● 데이터를 서로 다른 클래스로 분류, 객체 분류 (Classification)
● 객체 검출 (Object Detection)
● 정상 데이터, 이상치 탐지  (Anomaly Detection)

-생성 모델: 주어진 테이터를 통해 데이터 분포를 학습, 새로운 데이터를 생성
-생성 모델의 어려움
● 복잡한 모든 특성의 분포를 알아야한다.
● 판별 모델과 달리 데이터에 대한 정량적 평가가 어렵다. (평가 지표)



-Likelihood: 주어진 데이터가 특정 모델(분포)에서 나왔을 가능성. Probability(확률)과는 다르다


-생성 모델의 최대 Likelihood 추정법
● 쿨백-라이블러 발산 (KL 발산): 최대 Likelihood 최적화에 활용 가능한 기준이 되었지만, 데이터의 정확한 분포를 알 수 없다. (데이터 샘플을 많이 모아서 경험적으로 KL 발산을 최소화하는 방향으로 학습할 수 있다고 함.)



-판별 모델의 평가지표
● Accuracy
● Precision (정밀도)
● Recall (재현율)
● F1

-생성 모델의 평가가 어려운 이유
● 판별 모델과 달리 정답이 존재하지 않아 결과를 직접적으로 피할 대상이 없음.
● 훈련 데이터를 정답으로 쓰면 훈련 데이터를 그대로 복제해버림...
● 생성된 결과에 사람의 주관이 들어감.

-생성 모델 평가지표
● Fidelity (품질): 좋은 데이터를 생성
● Diversity (다양성): 다양한 데이터를 생성
● Feature Distance (특징 거리): 훈련에 사용한 원본 데이터와 생성된 결과물을 비교. (단순한 방법)

● Inception Score (IS): GAN을 평하기 위한 지표.  예리함(Sharpness), 다양성(Diversity) 2가지를 고려(Entropy). Entropy가 높으면 예측이 어려운 것. Entropy가 낮아야한다.
   IS = Sharpness * Diversity

  분류기(Classification) 모델의 훈련 데이터 셋과 다른 데이터를 생성하면 제대로 평가하기 어렵다는 한계점이 있고, 클래스 구분이 안 되면 평가를 못한다.
  IS가 높은 데이터를 생성하면 계속 같은 데이터만 생성한다. (오로지 생성된 데이터만을 이용해 계산해버린다...)
  여러모로 점수 조작이 가능하다.

  선명하면 특정 클래스로 분류될 확률이 높다. & 다양하면 각 클래스에 고르게 분포된다.
  다양성과 품질을 모두 고려했지만, ImageNet pretrained Classifier를 활용하기 때문에 ImageNet이 아닌 경우 측정이 어렵고 다양한 약점이 있다.
  
● Frechet Inception Distance (FID): 생성된 데이터의 특징 벡터를 이용해 훈련 데이터와의 거리를 계산. 거리가 낮을수록 좋음. (분류기는 활용하지 않고 특징 추출기로만 사용)
 훈련 데이터, 생성 데이터, 두 분포를 정규분포로 가정, 두 분포의 FID 거리를 계산
 특징의 평균 유사도(Fidelity), 특징의 분산 유사도(Diversity)

 FID는 Fidelity, Diversity를 각각 평가할 수 없다. 그래도 사용된다.

 특징 분포간 거리를 측정하는 지표
 다양성과 품질을 모두 고려, ImageNet pretrained Classifier를 활용했지만 ImageNet이 아니어도 평가 가능. (Diversity, Fidelity(품질) 두 지표를 각각 측정할 수 없다.)

 
 
 
