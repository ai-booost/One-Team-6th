### 2025-02-28

### TIL


#### 생성 모델: 필수적인 정보로부터 데이터 분포를 학습, 새로운 데이터를 생성

#### 딥러닝 기반 생성 모델
- 오토인코더(VAE): 입력 데이터를 저차원으로 압축 후, 다시 입력데이터와 비슷하게 출력.
- GANs: 생성기와 판별기가 경쟁하면서 데이터 생성.
- Diffusion 모델: 확산(Forward)과 역산(Revers)를 통해 점진적으로 이미지 생성.

![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-28%20232108.png)

#### GAN이 더 나은점
- 샘플 생성 속도 (GAN은 한 번에 이미지를 생성. Diffusion 모델은 확산, 역산의 여러 단계를 거치기 때문에 느림)
- 낮은 계산량. (GPU)

#### Diffusion이 더 나은점
- 다양한 이미지 생성
- 더 고품질 이미지 생성 가능
- 다양한 조건 적용 가능 (텍스트, 스타일, 손상복원 등)
- 3D 이미지 생성, 영상 생성
<br>

#### 판별 모델의 평가지표
- Accuracy
- Precision (정밀도)
- Recall (재현율)
- F1

#### 생성 모델의 평가지표
- 평가의 어려움: 생성된 결과에 대한 정량적 기준이 부족하고, 주관적인 평가가 필요.
- Fidelity (품질): 생성된 데이터가 실제 데이터에 얼마나 가까운지.
- Diversity (다양성): 생성된 데이터가 얼마나 다양한지를 평가.
- IS (Inception Score): 데이터의 예리함과 다양성을 평가하는 지표.
- FID (Frechet Inception Distance): 훈련 데이터와 생성 데이터 간의 특징 벡터 거리로 품질과 다양성을 종합적으로 평가.
  <br>FID는 Fidelity, Diversity를 각각 평가할 수 없다. 그래도 사용된다.
<br>

- Improved Precision: 생성된 데이터가 실제 데이터와 얼마나 일치하는지 측정. 실제 데이터 분포 내의 생성된 데이터 / 생성된 데이터
  ![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-03-01%20093200.png)

- Improved Recall: 실제 데이터가 생성된 데이터와 얼마나 유사한지 측정. 생성된 데이터 분포 내의 실제 데이터 / 실제데이터
  ![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-03-01%20093214.png)

- Improved Precision & Recall은 너무 민감하고, 계산량이 많아 Density, Coverage로 개선함.
- Density: 반경의 합집합이 아닌 가중 합집합으로 계산. 이상치에 대해 덜 민감해진다.
- Coverage: 생성된 데이터에 대해 매번 계산하지 않고, 실제 데이터 집합으로 미리 계산해 안정적이고 계산량 감소-

<br>

#### 조건부 생성 모델: 특정 조건을 기반으로 데이터를 생성하는 모델.

#### 조건부 생성 모델 평가지표:
- Intra FID: 특정 클래스의 데이터와 생성된 데이터의 FID.
- LPIPS: 데이터 간 유사도를 통해 다양성 측정.
- CLIP: 텍스트-이미지 관계를 평가하는 지표, 주로 텍스트 조건을 기반으로 이미지를 생성할 때 사용.







<br><br><br><br>
### 자세한 내용

#### 생성 모델: 필수적인 정보로부터 데이터 분포를 학습, 새로운 데이터를 생성

#### 고전 생성 모델: 확률 분포를 추정하고 근사한다.
- 가우시안 혼합 모델: 여러 개의 가우시안 분포(정규분포)를 조합하여 데이터를 모델링 하는 확률 기반 생성 모델.
데이터가 여러 개의 정규분포에서 생성되었다고 가정하고, 각 데이터가 어떤 정규분포에서 나왔는지 확률적으로 결정하는 모델.
- 제한된 볼츠만 머신: 볼츠만 분포, classification 같이 feature를 출력하는 것과 흡사하다.
- 심층 신뢰망(DBN): 볼츠만 머신 여러 층 이은거.
- 자기 회귀 기반의 생성 모델: 이전까지 생성한 것을 바탕으로 추정

#### 딥러닝 기반의 생성 모델
- 오토 인코더(VAE): 입력 데이터를 저차원으로 압축했다가 다시 원래 데이터로 복원하는 비지도 학습 신경망 모델. 시간이 갈수록, 분포 개선, 학습 개선, 벡터 양자화, 고성능, 고해상도로 발전해갔다.
- GANs: 판별기와 생성기, 두 신경망이 경쟁하면서 학습하는 모델. 생성기는 판별기를 속일 가짜 데이터를 만들고, 판별기는 생성기가 만든 가짜 데이터와 진짜 데이터를 판별하며 경쟁한다.
 시간이 갈수록, 더 높은 성능, 다양한 도메인으로 확장한다.
- 확산 모델(Diffusion Model): 확산(Forward)과 역산(Reverse)으로 이루어져있다. 시간이 갈수록, 생성 방식, 모델 개선, 다양한 도메인이 가능해지고 개인화 방법이 등장했다.




#### 판별 모델: 주어진 데이터를 통해 데이터 사이의 경계를 예측 (로지스틱 회귀, 분류)
- 데이터를 서로 다른 클래스로 분류, 객체 분류 (Classification)
- 객체 검출 (Object Detection)
- 정상 데이터, 이상치 탐지  (Anomaly Detection)

#### 생성 모델: 주어진 테이터를 통해 데이터 분포를 학습, 새로운 데이터를 생성
#### 생성 모델의 어려움
- 복잡한 모든 특성의 분포를 알아야한다.
- 판별 모델과 달리 데이터에 대한 정량적 평가가 어렵다. (평가 지표)


#### Likelihood: 주어진 데이터가 특정 모델(분포)에서 나왔을 가능성. Probability(확률)과는 다르다
![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-28%20233701.png)

![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-02-28%20233643.png)


#### 생성 모델의 최대 Likelihood 추정법
- 쿨백-라이블러 발산 (KL 발산): 최대 Likelihood 최적화에 활용 가능한 기준이 되었지만, 데이터의 정확한 분포를 알 수 없다. (데이터 샘플을 많이 모아서 경험적으로 KL 발산을 최소화하는 방향으로 학습할 수 있다고 함.)



#### 판별 모델의 평가지표
- Accuracy
- Precision (정밀도)
- Recall (재현율)
- F1

#### 생성 모델의 평가가 어려운 이유
- 판별 모델과 달리 정답이 존재하지 않아 결과를 직접적으로 피할 대상이 없음.
- 훈련 데이터를 정답으로 쓰면 훈련 데이터를 그대로 복제해버림...
- 생성된 결과에 사람의 주관이 들어감.

#### 생성 모델 평가지표
- Fidelity (품질): 좋은 데이터를 생성
- Diversity (다양성): 다양한 데이터를 생성
- Feature Distance (특징 거리): 훈련에 사용한 원본 데이터와 생성된 결과물을 비교. (단순한 방법)

- Inception Score (IS): GAN을 평하기 위한 지표.  예리함(Sharpness), 다양성(Diversity) 2가지를 고려(Entropy). Entropy가 높으면 예측이 어려운 것. Entropy가 낮아야한다.
   IS = Sharpness * Diversity

  <br>분류기(Classification) 모델의 훈련 데이터 셋과 다른 데이터를 생성하면 제대로 평가하기 어렵다는 한계점이 있고, 클래스 구분이 안 되면 평가를 못한다.
  <br>IS가 높은 데이터를 생성하면 계속 같은 데이터만 생성한다. (오로지 생성된 데이터만을 이용해 계산해버린다...)
  <br>여러모로 점수 조작이 가능하다.

  <br>선명하면 특정 클래스로 분류될 확률이 높다. & 다양하면 각 클래스에 고르게 분포된다.
  <br>다양성과 품질을 모두 고려했지만, ImageNet pretrained Classifier를 활용하기 때문에 ImageNet이 아닌 경우 측정이 어렵고 다양한 약점이 있다.
  
- Frechet Inception Distance (FID): 생성된 데이터의 특징 벡터를 이용해 훈련 데이터와의 거리를 계산. 거리가 낮을수록 좋음. (분류기는 활용하지 않고 특징 추출기로만 사용)
 <br>훈련 데이터, 생성 데이터, 두 분포를 정규분포로 가정, 두 분포의 FID 거리를 계산
 <br> 특징의 평균 유사도(Fidelity), 특징의 분산 유사도(Diversity)
 <br>FID는 Fidelity, Diversity를 각각 평가할 수 없다. 그래도 사용된다.
 <br>특징 분포간 거리를 측정하는 지표
 <br>다양성과 품질을 모두 고려, ImageNet pretrained Classifier를 활용했지만 ImageNet이 아니어도 평가 가능. (Diversity, Fidelity(품질) 두 지표를 각각 측정할 수 없다.)

- Close to(근방): 반지름이 r인 범위 내에 존재하면 근방에 속하는 데이터로 간주
- 생성 모델에서의 Precision: 생성된 데이터 중에, 실제 데이터 분포에 가까운 데이터 (품질). 실제 데이터 분포 내의 생성된 데이터/생성된 데이터
  ![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-03-01%20093200.png)

- 생성 모델에서의 Recall: 실제 데이터 중에, 생성된 데이터 분포에 가까운 데이터 (다양성). 생성된 데이터 분포 내의 실제 데이터 / 실제데이터
  ![image](https://github.com/JeongJunSeong/One-Team-6th/raw/jjs/TIL/jjs/Image/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202025-03-01%20093214.png)

- Improved Precision & Recall의 단점: 일부 데이터만 임베딩 위치가 변해도 값이 크게 변한다.(평가지표 불안정)
 <br>실제 데이터와 생성된 데이터의 분포가 동일해도 샘플링에 따라 점수가 낮을 수 있다.
 <br>매개변수에 민감하고 계산량이 많다.
 <br>단점 완화로 Density, Coverage가 있다.

- Density: 반경의 합집합이 아닌 가중 합집합으로 계산. 이상치에 대해 덜 민감해진다.
- Coverage: 생성된 데이터에 대해 매번 계산하지 않고, 실제 데이터 집합으로 미리 계산해 안정적이고 계산량 감소


#### 일반 생성 모델: 데이터 분포 p(X)를 학습. 생성되는 데이터의 의미를 제어할 수 없음.
#### 조건부 생성 모델: 데이터 분포 p(X|Y)를 학습. 특정 조건을 만족하는 데이터를 생성 가능.
<br>IS, FID는 다양하고 품질이 높으면 좋은 모델로 평가하기 때문에, 조건부 생성 모델 평가로 쓰기 좋진 않다.

#### 조건부 생성 모델 평가지표
- Intra FID: 특정 클래스 내의 데이터와 특정 클래스를 조건으로 생성되는 데이터에 계산되는 FID
 <br>사전훈련된 분류기에 크게 의존하고, 조건부 생성을 제대로 못 하고 동일한 데이터만 생성해도 감점이 없다.
 
- CAS(Classification Accuracy Score): 사전훈련된 분류기의 반대 과정. 생성 모델마다 분류기를 다시 학습해야한다.
- LPIPS: 모델 특징 비교를 통해 데이터의 유사도를 측정한다. 사전훈련된 분류기의 특성 사이의 유사도 측정.
 원본 영상과 유사도가 낮으면 다양하게 생성했다고 해석한다.
- CLIP: Text-Image 관계에 대한 평가지표. CLIP를 특징 추출기로 활용하거나 유사도를 측정한다.

 
