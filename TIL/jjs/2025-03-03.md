### 2025-02-28

### TIL

<br>

#### 오토 인코더: 입력 데이터의 패턴을 학습하여 데이터를 복원하는 모델


#### 오토 인코더의 구조
- 인코더: 데이터를 저차원 잠재표현으로 축소
- 디코더: 저차원 잠재표현으로부터 데이터를 재구성(Reconstruction)
- 손실함수: MSE, BCE(픽셀 값이 0~1 범위로 정규화된 경우, sigmoid 사용). MSE를 더 주로 사용.(흐릿한 이미지가 나오는 이유?)


####  오토 인코더의 활용
- 학습한 오토 인코더의 인코더 부분을 특징 추출기로 활용
- 잠재 벡터로부터 분류, 클러스터링(비지도) 문제 해결
- 이상치 탐지: 재구성 했을 때 MSE가 크게 나오면 이상치

<br>

```python
"""
인코더
arguments:
    latent_dim: 잠재 벡터의 차원
"""

class Encoder(nn.Module):
    def __init__(self, latent_dim: int=20):
        super().__init__()

        self.fc1 = nn.Linear(784, 256)    # mnist 입력사이즈 28x28, 784 => 256
        self.fc2 = nn.Linear(256, 128)    # 256 => 128
        self.fc_mean = nn.Linear(128, latent_dim) # 128 => latent_dim, 차원축소

    def forward(self, x: torch.Tensor):
        x = x.view(x.size(0), -1)
        x = F.leaky_relu(self.fc1(x), negative_slope=0.2)
        x = F.leaky_relu(self.fc2(x), negative_slope=0.2)
        z = F.leaky_relu(self.fc_mean(x))
        return z

"""
디코더
arguments:
    latent_dim: 잠재 벡터의 차원
"""
class Decoder(nn.Module):
    def __init__(self, latent_dim: int=20):
        super().__init__()

        self.fc1 = nn.Linear(latent_dim, 128)
        self.fc2 = nn.Linear(128, 256)
        self.fc3 = nn.Linear(256, 784)    # 차원축소 한 것을 다시 확장

    def forward(self, z: torch.Tensor):
        z = F.leaky_relu(self.fc1(z), negative_slope=0.2)
        z = F.leaky_relu(self.fc2(z), negative_slope=0.2)
        x_hat = F.sigmoid(self.fc3(z))      # pixel은 0~1까지의 범위를 갖고있어서 sigmoid 사용
        x_hat = x_hat.view(x_hat.size(0), 1, 28, 28)  # (배치사이즈, 채널, 높이, 너비)

        return x_hat
```


#### 코드 중간에 있는 ? 내용
```python
train_size += label.size(0) # 모든 배치에서 샘플 개수를 직접 더하는 방식. 정확한 평균 손실을 구하기 위해 train_size를 직접 누적하는 것이 일반적

len(train_loader.dataset)는 데이터셋 전체 크기를 가져오는 방식. 일반적으로는 train_size와 같지만, 데이터 샘플링, 가중치 적용 등 특수한 경우 다를 수 있음 

train_epoch_loss /= train_size  # loss를 batch 단위로 계산하기 때문
```

#### 2차원으로 축소하는 알고리즘으로는 t-분포 확률적 임베딩 (t-distributed Stochastic Neighbor Embedding, t-SNE)를 사용합니다. 오토 인코더로 학습한 잠재 벡터 (latent_dim 차원)를 t-SNE로 2차원 평면에 시각화합니다.
오토인코더 시각화 용도로 쓰는 듯

<br>

#### 변분 오토인코더: 오토인코더와 동일한 구조(Encoder + Decoder)를 가지는 생성모델
- 잠재변수가 표준정규분포를 따른다고 가정 p(z)
- 각 특징을 확률 분포로 정의, 샘플링 수행
- 데이터 분포를 알고싶지만 직접 계산하지 못하고, 간접적으로 계산하여 최대화 => 가능도(Likelihood) => ELBO
- 손실함수: MSE, BCE(픽셀 값이 0~1 범위로 정규화된 경우, sigmoid 사용). 주로 BCE 사용(더 선명한 이미지 만들어지기 쉬움. 하지만 결과는 별로 선명해보이지 않다.), KL-Divergence 필수로 추가. 
- 손실함수 미분불가능 => 표준정규분포에서 샘플링해서 변환하면 미분 가능(재매개변수화)
- 의미있는 잠재 표현 학습 q(z|x)
- 흐릿한 이미지를 생성하는 경향이 있다

```python
class VariationalEncoder(Encoder):
    def __init__(self, latent_dim: int=20):    
        super().__init__(latent_dim=latent_dim)    # 오토인코더의 인코더 상속

        self.fc_log_var = nn.Linear(128, latent_dim)    # 추가레이어

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = F.leaky_relu(self.fc1(x), negative_slope=0.2)
        x = F.leaky_relu(self.fc2(x), negative_slope=0.2)\
        mean = self.fc_mean(x)

        # 오토 인코더와의 주요 차이점
        log_var = self.fc_log_var(x)

        return mean, log_var    # mean만 반환하던 오토인코더와 다르게 mean과 log_var 두 개를 반환

    # 디코더는 상속받은 그대로
    # 그 외 Autoencoder 클래스를 상속받고, reparameterize(재매개변수화) 함수가 포함된 VariationalAutoencoder를 만듬
    # def KLDivergenceLoss(mean, log_var) KL-Divergence 가져다 쓴다.
    
```


<br>

#### VQVAE (벡터 양자화 변분 오토인코더)
- 실제 이미지나 텍스트는 유한한 특성으로 표현될 수 있음. (입력 데이터를 저차원의 벡터 공간으로 압축한 것, 임베딩 벡터)
- 유한한 잠재표현을 활용하는 변분 오토인코더
- 손실함수: VAE처럼 ELBO. 잠재변수에 대한 기울기를 인코더 출력에 전달하면 역전파가 가능해지는 듯 하다...

#### VQVAE-2
- 고해상도 이미지를 다루기 위해 계층구조 사용.
- Top 레벨이 Bottom 레벨을 참조한다.
- 위층(Top Level): 전역적인 특징 (러프), Self Attention 사용
- 아래층(Bottom Level): 국소적인 특징 (디테일), 위층의 잠재 벡터를 추가로 입력받음.
- 사전학습된 분류기로 활용됨. Diffusion 모델에 쓰이는 등 다른 모델의 일부로 사용됨.
