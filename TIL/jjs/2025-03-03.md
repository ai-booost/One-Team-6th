### 2025-02-28

### TIL

<br>

#### 오토 인코더: 입력 데이터의 패턴을 학습하여 데이터를 복원하는 모델


#### 오토 인코더의 구조
- 인코더: 데이터를 저차원 잠재표현으로 축소
- 디코더: 저차원 잠재표현으로부터 데이터를 재구성(Reconstruction)
- 손실함수: MSE


####  오토 인코더의 활용
- 학습한 오토 인코더의 인코더 부분을 특징 추출기로 활용
- 잠재 벡터로부터 분류, 클러스터링(비지도) 문제 해결
- 이상치 탐지: 재구성 했을 때 MSE가 크게 나오면 이상치

<br>

```python
"""
인코더
arguments:
    latent_dim: 잠재 벡터의 차원
"""

class Encoder(nn.Module):
    def __init__(self, latent_dim: int=20):
        super().__init__()

        self.fc1 = nn.Linear(784, 256)    # mnist 입력사이즈 28x28, 784 => 256
        self.fc2 = nn.Linear(256, 128)    # 256 => 128
        self.fc_mean = nn.Linear(128, latent_dim) # 128 => latent_dim, 차원축소

    def forward(self, x: torch.Tensor):
        x = x.view(x.size(0), -1)
        x = F.leaky_relu(self.fc1(x), negative_slope=0.2)
        x = F.leaky_relu(self.fc2(x), negative_slope=0.2)
        z = F.leaky_relu(self.fc_mean(x))
        return z

"""
디코더
arguments:
    latent_dim: 잠재 벡터의 차원
"""
class Decoder(nn.Module):
    def __init__(self, latent_dim: int=20):
        super().__init__()

        self.fc1 = nn.Linear(latent_dim, 128)
        self.fc2 = nn.Linear(128, 256)
        self.fc3 = nn.Linear(256, 784)    # 차원축소 한 것을 다시 확장

    def forward(self, z: torch.Tensor):
        z = F.leaky_relu(self.fc1(z), negative_slope=0.2)
        z = F.leaky_relu(self.fc2(z), negative_slope=0.2)
        x_hat = F.sigmoid(self.fc3(z))      # pixel은 0~1까지의 범위를 갖고있어서 sigmoid 사용
        x_hat = x_hat.view(x_hat.size(0), 1, 28, 28)  # (배치사이즈, 채널, 높이, 너비)

        return x_hat
```


#### 코드 중간에 있는 ? 내용
```python
train_size += label.size(0) # 모든 배치에서 샘플 개수를 직접 더하는 방식. 정확한 평균 손실을 구하기 위해 train_size를 직접 누적하는 것이 일반적

len(train_loader.dataset)는 데이터셋 전체 크기를 가져오는 방식. 일반적으로는 train_size와 같지만, 데이터 샘플링, 가중치 적용 등 특수한 경우 다를 수 있음 

train_epoch_loss /= train_size  # loss를 batch 단위로 계산하기 때문
```

#### 2차원으로 축소하는 알고리즘으로는 t-분포 확률적 임베딩 (t-distributed Stochastic Neighbor Embedding, t-SNE)를 사용합니다. 오토 인코더로 학습한 잠재 벡터 (latent_dim 차원)를 t-SNE로 2차원 평면에 시각화합니다.
Grad-CAM 같은 역할인 것 같음
