### 2025-03-05

### TIL

<br>

#### GANs (적대적 생성 신경망): Generator(생성자), Discriminator(판별자) 두가지 모델이 서로 속이고 판별하면서 경쟁을 해 학습하는 신경망.

#### Generator (생성 모델): 임의의 노이즈를 입력으로 받아 생성된 데이터를 출력. 판별자를 진짜 데이터인 것처럼 속여야한다.

#### Discriminator (판별 모델): 생성된 데이터를 입력으로 받아 실제 데이터(Real)인지 생성된 데이터(fake)인지 출력. 생성자가 만든 데이터의 진위를 파악해야한다.

#### GANs 목적함수: 둘은 적대적으로 학습됨 (min & max)
- Two-Player Zero-Sum Game
![이미지 설명](https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_03.jpg)

- Discriminator는 최대화
- Generator는 최소화
  
<br>

- GANs 목적 함수는 실제로는 잘 동작하지 않는다. 그래서 반대방향으로 개선되게 된다.
![이미지 설명](https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_090759749.jpg)

<br>

- GANs의 목적 함수는 생성 데이터 분포와 실제 데이터 분포가 동일한 분포에서 최적된다.
![이미지 설명](https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_01.jpg)
![이미지 설명](https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_02.jpg)




#### 다양한 목적 함수
![이미지 설명](https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_04.jpg)


#### GANs의 장점과 한계
- GANs의 결과물은 상대적으로 뚜렷하고, 빠르게 생성할 수 있다.
- 생성 모델이 판별 모델을 속일 수 있는 일부 데이터만 생성하는 현상이 생길 수 있다.
- 다양성이 낮다.

<br> 

#### 생성 모델 구현
![이미지 설명](https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20091349.png)

- 풀링(Pooling) 레이어와 완전연결(Fully Connected) 레이어를 대체하여 전치 합성곱(Tranpose Convolution)을 사용하여 깊은 신경망을 구성한다.
- 전치 합성곱 레이어의 가중치를 평균 0, 표준편차 0.02인 정규분포로 초기화한다.
- ConvTranspose2d()를 사용해 입력의 크기를 키운다.
- 출력 전 레이어를 제외하고 배치 정규화(Batchnorm)을 사용한다.
- ReLU 활성화 함수를 사용한다. 마지막 출력을 위해서는 tanh 활성화 함수를 사용한다.
<br>

<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20091630.png" width="75%">



#### 판별 모델 구현
- 합성곱(Convolution) 레이어만 사용하여 깊은 신경망을 구성한다.
- 입력 데이터에 연결된 레이어를 제외하고 배치 정규화(Batchnorm)을 적용한다. # 생성자의 반대.
- LeakyReLU 활성화 함수를 사용한다. 마지막 레이어에서는 시그모이드 활성화 함수를 적용하여 [0,1] 범위의 입력 이미지가 실제 이미지일 확률을 출력한다.
<br>

<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20091644.png" width="50%">

아크리프

<br>

#### 학습 파라미터: 0.0002, Adam B(베타)1: 0.5

<br>

#### 손실함수
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20092859.png" width="100%">

<br>

#### 판별자 손실함수
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20092923.png" width="100%">

<br>

#### 생성자 손실함수
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20092933.png" width="100%">

<br>

#### 학습과정: 판별자와 생성자를 학습할 때 모두 생성자의 출력 이미지  G(z) 가 사용된다. pytorch에서는 판별자를 먼저 학습할 때 torch.detach()를 사용하여 생성자에게 역전파가 일어나지 않도록 그래디언트를 계산하지 않게 한다.
- GAN은 잠재 벡터를 이용하므로 잠재벡터 샘플링
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20093038.png" width="85%">

- fake_prob = discriminator(fake_data.detach()).view(-1) # D(G(z)) 계산하여 1차원 벡터로 변환, 판별자 학습 시, 반드시 detach() 붙여줘야한다.
- 판별자용 loss
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20093131.png" width="85%">

- fake_prob = discriminator(fake_data).view(-1) # D(G(z)) 계산하여 1차원 벡터로 변환. 위의 fake_prob과 동일. 생성자 학습 시, detach()만 제거
- 생성자용 loss
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/스크린샷%202025-03-06%20093145.png" width="85%">



<br>

#### 조건부 생성 모델 기반의 영상 조작
- 회귀모델: 변환된 이미지를 생성하는게 아니라, 회귀 모델로 픽셀값을 예측해서 흐릿한 이미지가 만들어짐. 픽셀 요소별 L1 손실, L2 손실 활용
- Pix2pix: 이미지 대 이미지
- CycleGAN
- BiCycleGAN
- StarGAN
- InstaGAN
- LostGANs
- SPADE
- Hyper Style
- GAN-CLS: 텍스트 대 이미지
- GigaGAN

#### Pix2pix
- U-Net 기반의 생성모델.
- 인코더-디코더 구조에 Skip Connection을 추가해, 영상 세부 사항을 잘 유지했다.
- 기존 GANs의 판별 모델은 저해상도 모델. 고해상도를 위해 패치 기반의 PatchGANs의 판별 모델 차용
- L1 정규화 항 추가
- 이미지를 잘 생성하지만, 데이터가 반드시 쌍으로 존재해야하는 단점이 있음. 현실적으로 그런 데이터를 확보하는 것은 어렵다.

#### CycleGAN
- Cycle Consistent: 상호변환이 가능. domain끼리 변환.(한국어 -> 영어, 영어 -> 한국어)
- 입력 이미지로 복원 가능한 정도까지만 이미지를 변환, 원본 손실을 최소화한다.
- 생성 모델, 판별 모델이 2개씩, 총 4개가 필요하다.
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_06.jpg" width="85%">
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_07.jpg" width="85%">
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_08.jpg" width="85%">
<br>

- CycleGAN은 양방향 변환이 가능하며, 양방향 모두 우수한 결과를 보임.
- 결국엔 변환이기 때문에 배경이 약간 흐려지긴 한다.
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_10.jpg" width="85%">
<br>

#### BiCycleGAN
- 하나의 영상이 다른 도메인에서 여러 양상으로 그려질 수 있음.
<br>

#### StarGAN
- 3개 이상의 도메인간 변환을 수행함
- 그 전에는 여러 도메인을 할려면 필요한 네트워크가 기하급수적으로 증가했다. StarGAN에서 해결
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_11.jpg" width="85%">
<br>

#### InstaGAN (2019)
- 형태 차이가 큰 도메인간 변환이 가능해짐.
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_12.jpg" width="85%">
<br>

#### LostGANs (2019)
- 공간 구조로 이미지 생성 가능
- 이미지 매핑 보존이 가능
- 이미지 매핑 보존을 기반으로 위치 이동 등 이미지 재구성 가능
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_13.jpg" width="85%">
<br>

#### SPADE (GauGAN) (2019)
- 의미 분할 정보를 이용해, 이미지 생성 단계에서 객체 추가, 변경이 가능
- 같은 의미 영역에 대해 다양한 데이터 생성 가능
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_14.jpg" width="85%">
<br>

#### Pretrained GAN을 활용한 이미지 변환 (2022)
- 이미지만을 활용해 학습한 모델의 잠재 공간을 분석, 활용해 이미지 변환에 활용
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_15.jpg" width="85%">
<br>


## 이런 식으로 GAN은 형태변환도 자유로워지고 이미지를 옮길수도 있게 되고 발전돼왔다.

#### GAN-CLS
- 텍스트 입력으로 이미지 생성
- 단어보다 문장으로 더 풍부한 이미지 생성 가능
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_16.jpg" width="85%">
<br>
  
- 이미지는 한번에 생성되므로, 중요한 시각적 정보를 잘 인코딩하는 텍스트 특징 표현을 훈련해야함.
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_17.jpg" width="85%">
<br>

- 기존의 GAN 손실함수는 [실제이미지 + 정확한 설명 (참), 생성 이미지 + 정확한 설명(거짓)] 만 있었지만, GAN-CLS에서 [실제이미지 + 부정확한 설명 (거짓), 생성 이미지 + 정확한 설명(거짓)] 도 고려되게 됐다.
- 기존에는 훈련 텍스트와 훈련 이미지를 일대일로 매칭한 것을 훈련해서 테스트 시 성능이 하락했지만, 텍스트 특징 벡터에 대한 보간법으로 완화했다.


#### GiGA GAN (2023)
- GANs를 이용한 고해상도 텍스트 대 이미지 생성
- 다른 생성 모델처럼 모델의 규모와 데이터를 매우 크게 학습, 텍스트 기반으로 고해상도 이미지 생성
- 저화질 생성 이후 고화질 변환 모델로 화질 개선 (Multi-stage Generation)
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_18.jpg" width="85%">
<br>

1. 입력받은 텍스트를 사전 훈련된 CLIP 인코더와 레이어 T를 통해 임베딩
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_19.jpg" width="85%">
<br>

2. 스타일 네트워크 M은 스타일 벡터 w를 출력
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_20.jpg" width="85%">
<br>

3. 생성 네트워크 G는 텍스트 임베딩과 스타일을 입력으로 받아 이미지를 생성
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_21.jpg" width="85%">
<br>

4. 전역 정보를 통해 스타일을 생성, 지역 정보는 피라미드형 구조에 계속하여 조건 정보로 활용 (그 이후는 그냥 강의 자료에 자세히...)
<img src="https://raw.githubusercontent.com/JeongJunSeong/One-Team-6th/jjs/TIL/jjs/Image/KakaoTalk_20250306_085816171_22.jpg" width="85%">


<br>

#### diffu 
