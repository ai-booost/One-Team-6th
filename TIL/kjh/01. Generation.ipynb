{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastcampus\n",
    "## 생성모델의 개요\n",
    "### 생성모델(Generative models)\n",
    "데이터는 저차원의 필수적인 정보로부터 생성 가능하다는 가정 하에 분포를 학습하여, 새로운 데이터를 생성하는 모델  \n",
    "- 데이터는 저차원의 필수적인 정보로 부터 생성 가능하다? = 하나의 image는 수많은 요소로 이루어져 있다.(ex. 어른+안경+남성+미소+...)  \n",
    "\n",
    "\n",
    "### 확률 분포 추정과 근사\n",
    "1. 가우시안 혼합 모델 = 정규분포\n",
    "- 여러 가우시안 분포를 활용해서 실제 데이터와 비슷하게 맞추는 방식\n",
    "2. 제한된 볼츠만 머신 = 볼츠만 분포\n",
    "- 인공신경망 기능의 생성모델\n",
    "- 에너지가 낮을 수록 확률밀도 함수가 커짐.\n",
    "- 목적함수를 정의하고 최적화 하는 방식\n",
    "3. 심층 신뢰망(DBN) = 여러 층의 RBM\n",
    "- 제한된 볼츠만 머신을 쌓은 듯한 모양을 하고 있음. 출력을 입력으로 다시 받는 형식\n",
    "4. 자기회귀(NADE) = 자기 회귀 기반의 생성모델\n",
    "- 현재의 픽셀값을 이전의 픽셀값에 의거\n",
    "\n",
    "\n",
    "### 2014년 이후 딥러닝 기반의 생성모델\n",
    "1. 변분 오토 인코더 (VAE)\n",
    "- 흐린 영상 생성의 문제점 = AAE/LVAE로 발전 (분포 개선, 계층 모형) -> WAE, Beta-VAE, VQ-VAE 등으로 다시 발전(학습 개선, 벡터 양자화화)\n",
    "- 2019년 이후에는 VQ-VAE-2 (고성능, 고해상도 모델 제안), NVAE(Deep VAE) 가 나오면서 점점 발전하기 시작했다.\n",
    "2. 적대적 생성 신경망(GANs)\n",
    "- GANs, sGAN 발표 -> Deep Convolution GAN(DCGAN) -> 손실함수, 학습방법 연구 (LSGAN, WGAN)\n",
    "3. PixelR/CNN\n",
    "4. Normaliziing Flow\n",
    "5. 확산 모델(Diffusion Model)\n",
    "- 열확산 현상 이론 도입\n",
    "- 매우 느린 생성 속도가 단점이었지만 이를 해결할 수 있는 생성 방식 및 모델 개선을 통해 해결했다.\n",
    "- 여려 형태의 입력(TEXT, IMAGE, ...)를 받아 IMAGE를 생성할 수 있었다.\n",
    "- 높은 생성물 의미론 제어 방법 및 개인화 방법등장\n",
    "\n",
    "\n",
    "### 판별모델\n",
    "데이터 X가 주어졌을 때, 특성 Y가 나타날 조건부 확률을 직접적으로 반환하는 모델  \n",
    "= 주어진 데이터를 통해 데이터 사이의 경계를 예측  \n",
    "#### 판별 모델의 활용\n",
    "1. 어떤 데이터를 서로 다른 클래스로 분류해 주는 문제에 할용할 수 있음\n",
    "2. 정상 데이터에 대한 경께를 최대한 좁혀 이를 벗어나는 이상치를 감지하는 문제에도 응용이 가능 = 공장 불량품 찾기\n",
    "#### 로지스틱 회귀분석\n",
    "두 그룹의 경계를 곡선으로 FITTING 하기 위해 사용\n",
    "### 생성모델\n",
    "데이터 X와 특성 Y의 결합 분포/ Y가 주어질 때 X의 조건부 분포를 추정하는 모델  \n",
    "주어진 Y가 없는 경우, 데이터 주변(marginal)분포를  추정하는 모델\n",
    "\n",
    "\n",
    "주어진 데이터를 통해 데이터 분포를 학습함\n",
    "#### 생성 모델의 어려움\n",
    "1. 고차원 데이터를 모델링\n",
    "- 복잡한 모든 특성의 분포를 알아야함. (데이터는 저차원의 정보로 표현 할 수 있다는 가정을 활용함)\n",
    "2. 평가 지표\n",
    "- 판별 모델과 달리 생성된 데이터에 대한 정량적 평가가 어려움 (ex. 더 나은 결과물이 무엇인지 평가할 지표가 애매함)\n",
    "\n",
    "\n",
    "#### 생성모델의 활용\n",
    "1. 이미지의 품질 개선\n",
    "2. 맥락에 맞게 이미지 빈 공간 자동 완성\n",
    "3. 오래된 사진 복구 / 새로운 색감 부여\n",
    "4. ai 음악 생성\n",
    "\n",
    "\n",
    "### 생성 모델과 최대 가능도 추정\n",
    "#### 가능도(likelihood)\n",
    "모델 파라미터에 의존하는 분포를 따르는 n개의 데이터를 관찰 한 후, 데이터로부터 모델 파라미터를 추정하는 방법 = 가능도를 최대화 하는 파라미터 찾기  \n",
    "log-likelihood를 사용하는 이유 = 곱셈이 덧셈 형태로 바뀌고, 미분이 쉬워지기 때문 (수식적 해석이 쉬워짐)\n",
    "#### 최대 가능도 추정법(MLE:Maximum Likelihood Estimation)\n",
    "가능도를 치대화 하는 파라미터를 찾는 방법  \n",
    "일반적으로 가능도 함수의 미분을 통해 계산\n",
    "### 생성 모델의 학습\n",
    "1. 데이터 분포를 어떻게 모델링 할까? = 모델을 어떻게 학습시켜야 하는가?\n",
    "- 데이터의 분포와 모델을 가깝게 해야함.\n",
    "2. 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL-divergence) 최소화\n",
    "- 직관적으로 분포간 차이/거리 라고 이해하면 쉬움. 하지만 정확한 건 아님\n",
    "3. 하지만 우리는 데이터의 분포를 모르고 관측치 만 관측할 수 있음.\n",
    "\n",
    "\n",
    "## 생성모델의 평가지표\n",
    "### 판별모델의 평가지표\n",
    "1. 판별 모델은 정답(Ground Truth,GT)이 존재하므로 모델의 출력을 정답과 비교하기 용이하다.\n",
    "2. 범주형 데이터를 사용하는 경우(분류형)와 연속형 데이터(회귀 분석)를 사용하는 경우로 나눌 수 있다.\n",
    "- 범주형 데이터의 경우, 정확도/F-Score/ Recall 등의 여러 평가 지표가 존재하며 사용된다.\n",
    "- 연속형 데이터의 경우, MSE/MAE / R-squared/ 상관계수 등의 여러 평가지표가 존재하며 사용된다.\n",
    "### 생성모델의 평가가 어려운 이유\n",
    "1. 비교할 정답이 존재하지 않아 결과를 직접적으로 비교할 대상이 없음\n",
    "2. 훈련데이터를 정답으로 사용할 경우, 훈련 데이터를 그대로 복제하는 현상이 발생함 (ㄹㅇ 이걸 어캐 한거지?)\n",
    "3. 주관이 개입 될 여지가 있음 (같은 그림이지만 웃는건지 우는 것인지를 착각할 수 있음)\n",
    "### 생성모델의 평가지표\n",
    "#### 어떤 항목들을 평가해야 하는가?\n",
    "1. 충실도 : 이미지의 품질\n",
    "2. 다양성 : 이미지의 다양성\n",
    "#### 평가지표 종류\n",
    "1. IS(Inception Score)\n",
    "- Inception v3 모델을 분류기로 이용하여 GAN을 평가하기 위해 고안된 지표\n",
    "- 예리함과 다양성 두 가지를 주요하게 고려 (IS = Sharpness * Diversity)\n",
    "- 무질서도(Entropy) : 높을경우 -> 임의의 변수에 대해 예측되는 값이 많음 = 예측이 어려움\n",
    "- 예리함(Sharpness) : Entropy가 낮을수록 예리해짐\n",
    "- 다양성(Divergence) : 다양한 유형의 데이터가 분포\n",
    "- 한계:\n",
    "    1. 분류기 모델의 훈련 데이터 셋과 다른 데이터를 생성하는 경우 제대로 평가하기 어려움\n",
    "    2. 계속 같은 데이터를 생성(Mode Collapse), 기울기 기반(Gradient Based) 공격, 리플레이(Replay) 공격을 통해 점수 조작이 가능\n",
    "2. FID(Frechet Inception Distanch)\n",
    "- 낮을 수록 좋음\n",
    "- 생성된 데이터의 특징 벡터를 이용하여 훈련 데이터와의 거리를 계산\n",
    "- 한계\n",
    "    1. Fidelity와 Diversity를 각각 평가할 수 없음. = 어느쪽이 강조되었는지 혹은 균형 잡힌 모델인지 알 수 없음\n",
    "3. 개선된 정밀도, 재현율 (Improved Precision & Recoall)\n",
    "- 정밀도(Precision) : Positive 예측한 것 중 실제로 Positive인 경우 = TP/(TP+FP)\n",
    "- 재현율(Recall) : 실제 positive 한 것 들 중에서 옳바르게 예측한 경우 = TP/(TP+FN)\n",
    "- 한계: 이상치에 민감, 실제 데이터와 생성된 데이터의 분포가 동일하더라도 샘플링에 따라 점수가 낮을 수 있음\n",
    "\n",
    "\n",
    "4. 조건부 정확도 (Conditional Accuracy)\n",
    "- 레이블이 주어졌을 때, 데이터의 분포를 학습 = 특저조건을 만족하는데이터를 생성 가능\n",
    "5. LPIPS(Learned Perceptual Image Patch Similarity)\n",
    "- 모델 특징 비교를 통한 영상간 유사도 측정 = 우리가 어떻게 두 이미지가 비슷하다고 느끼는가\n",
    "- 원본 영상과 유사도가 낮다 = 더 다양하게 생성했다로 해석\n",
    "6. CLIP-Score\n",
    "- Text-image 관계를 학습한 CLIP을 특징 추출기로 활용해서 유사도를 측정함함\n",
    "## 오토 인코더와 변분 오토 인코더\n",
    "### 오토인코더\n",
    "입력 데이터의 패턴을 학습하여 데이터를 재건하는 모델(비선형 차원 축소기법으로 활용 가능)\n",
    "1. 인코더: 데이터를 저차원 잠재 표현으로 요약\n",
    "2. 디코더: 저차원 잠재 표현으로 부터 데이터를 재구성\n",
    "3. 손실 함수 : 잠재 표현으로부터 복구한 데이터와 입력 데이터의 MSE\n",
    "### 디노이징 오토 인코더\n",
    "입력 데이터에 random noise를 주입하거나 Dropout layer를 적용  \n",
    "노이즈가 없는 원래 데이터로 재구성\n",
    "#### 원리\n",
    "안개 속에서 멀리 있는 물체를 구별할 때, 데이터의 특성들을 더욱 정확히 학습함(가려져도 구별되는 특별한 특징을 학습함)  \n",
    "노이즈에 강건한 잠재 표현 (미세하게 변형된 데이터도 같은 잠재 벡터로 표현 되도록)\n",
    "\n",
    "\n",
    "### 오토 인코더 활용\n",
    "학습한 오토 인코더의 인코더 부분을 특징 추출기로 활용  \n",
    "잠재 벡터로부터 분류, 클러스터링 문제 해결  \n",
    "\n",
    "\n",
    "### 변분 오토 인코더(VAE)의 구조\n",
    "1. 데이터는 저차원의 잠재 변수로부터 생성된다는 가정을 기반에 두고 있음.\n",
    "2. 잠재 벡터의 분포는 표준정규분포를 따르게 만든다.\n",
    "\n",
    "\n",
    "### 변분 오토 인코더의 학습\n",
    "잠재 변수가 표중정규분포를 따른다고 가정(사전분포->p(z))  \n",
    "각 특징을 확률분포로 정의, 이로부터 샘플링을 수행함.  \n",
    "\n",
    "\n",
    "#### ELBO(Evidence of Lower BOund)\n",
    "현재 모델이 우리가 가진 현상을 얼마나 잘 설명하는가 = 가능도(likelihood)  \n",
    "직접 계산이 어려우니, 간접적으로 계산하여 최대화함.\n",
    "가능도는 계산이 안되지만 ELBO는 계산이 가능함. 따라서 ELBO를 최대화  \n",
    "\n",
    "\n",
    "#### VAE의 loss function\n",
    "재매개변수화 방법 이용  \n",
    "\n",
    "\n",
    "#### 변분 오토 인코더의 활용\n",
    "1. 잠재 벡터를 표준정규분포에서 샘플링, 디코더의 분포로붵 새로운 데이터를 생성\n",
    "2. 대표적인 특징은 잘 생성하지만 뿌연듯한 느낌이 많이 듦.\n",
    "3. 의미있는 잠재 표현을 학습할 수 있음. 이는 발전의 여지를 ㄴ남길 수 있다는 점에서 큰 장점임.\n",
    "#### 장점 & 단점\n",
    "1. 장점 : 데이터를 요약하는 유용한 잠재 표현을 찾을 수 있음\n",
    "2. 단점 : 가능도가 아닌 가능도의 하한을 최대화 하기 때문에 흐릿한 이미지를 생성하게 된다.\n",
    "\n",
    "### 벡터 양자화 변분 오토 인코더(VQVAE)\n",
    "유한한 잠재 표현형: 실제 이미지나 텍스트는 유한한 특성으로 표현할 수 있음.  \n",
    "이산 잠재 변수 (Discrete): 범주 K개의 D차원 임베딩 벡터  \n",
    "\n",
    "## 적대적 생성 신경망 (GANs)\n",
    "### GANs\n",
    "Generative, Adversarial Netsorks  \n",
    "적대적으로 학습하는 신경망들로 구성되며, 생성 모델로써 활용함  \n",
    "최적화가 어렵고 두개의 신경망이 있으므로 학습에 오래걸림  \n",
    "생성된 데이터의 다양성이 낮을 수 있음.\n",
    "### VAE vs GANs\n",
    "1. 생성방식\n",
    "- VAE의 생성 방식 : 입력 분포를 근사하는 과정에서 규제을 주며 데이터를 생성\n",
    "- GANs의 생성 방식 : 생성된 데이터오 실제 데이터를 판별하고 속이는 과정을 거치며 생성 모델을 개선\n",
    "2. 생성 결과\n",
    "- VAE의 결과물은 상대적으로 흐릿하고, 입력데이터와 유사한 형태로 생성\n",
    "- GANs의 결과물은 상대적으로 뚜렷하고, 입력데이터와 다른 형태의 데이터를 생성\n",
    "#### GANs 구조\n",
    "1. 데이터를 생성하는 생성모델과 데이터의 진위를 구별하는 판별모델(Discriminator)로 구성\n",
    "- 판별 모델: 생성된 데이터를 입력으로 받아 실제 데이터인지 생성된 데이터인지를 출력\n",
    "#### GANs 목적\n",
    "1. 생성 모델의 분포와 판별 모델의 예측을 지속적으로 갱신하면서 학습됨.\n",
    "- 임의의 초기 분포로부터 생성 모델이 데이터를 생성\n",
    "- 판별 모델이 분류; 판별 모델 갱신\n",
    "- 갱신된 판별 모델을 고정; 생성 모델 갱신\n",
    "- 반복 과정을 거쳐 생성 모델은 판별 모델이 구별할 수 없는 수준의 데이 터를 생성\n",
    "\n",
    "### 조건부 생성 모델\n",
    "생성 모델: 임의의 잠재 벡터로부터 데이터를 생성\n",
    "데이터를 잘 생성하나 그들의 의미는 제어할 수 없음\n",
    "\n",
    "#### 이미지 대 이미지 변환: 전통적 접근\n",
    "이미지 변환의 대표적인 예시: 색상 변환, 잔밤 변환, 스케치 채색 등  \n",
    "조건부 GANs이전에는 각 태스크별 모델과 손실 함수를 각각 정의해야 했음  \n",
    "#### pix2pix\n",
    "이미지 쌍이 있는 조건부 생성 모델 기반의 이미지 대 이미지 변환 프레임 워크를 제안\n",
    "- 이미지 특성별로 회귀 모형을 만드는 것이 아닌, 생성 모델이 변환된 이미지를 생성하자\n",
    "\n",
    "데이터가 반드시 쌍으로 존재해야 하기에, 데이터를 확보하는 것이 어려움\n",
    "ex)같은 위치의 다른 계절, 같은 위치와 같은 자세의 얼룩말과 말 등...\n",
    "\n",
    "#### cycleGAN\n",
    "상호 변환이 가능한 것; 한국어->영어 변환이 가능하다면 영어->한국어 변환도 가능해야함  \n",
    "입력 이미지로 복원 가능한 정도까지만 이미지를 변환하도록 하여 원본 손실을 최소화  \n",
    "\n",
    "하나의 입력, 다양한 출력- 하나의 영상이 다른 도메인에서 여러 양상으로 그려질 수 있음.\n",
    "\n",
    "#### StarGAN\n",
    "3개 이상의 도메인 간 변환을 수행함\n",
    "#### GigaGAN\n",
    "다른 생성모델처럼 모델의 규모와 데이터를 매우 크게 만들어 학습, 텍스트 기반으로 고해상도 이미지를 생성함\n",
    "저화질 생성 이후 고화질 변환 모델로 화질 개선 작업 수행\n",
    "- 기존 text2image의 패러다임을 따름\n",
    "## 확산 모델 (Difusion model)\n",
    "### 확산 확률 모델\n",
    "최근 활발히 연구되고 있는 모델  \n",
    "픽셀 값이 섞이고 번져가다가 마지막에는 균일한 농도의 noise가 되는 현상을 이용   \n",
    "#### DPM - 확률\n",
    "확산 현상을 시간에 따라 확률적 모델링  \n",
    "마르코프체인: 미래는 과거가 아닌 현재에만 의존한다.\n",
    "#### DPM - 구조\n",
    "정방향 확산: 데이터 -> 노이즈 (고정)\n",
    "- 이미지 파괴과정 = T = 1000 시점 동안 노이즈를 주입\n",
    "역반향 확산: 노이즈 -> 데이터 (학습)\n",
    "- 이미지 생성과정 = 노이즈를 제거하는 과정은 계산 불가\n",
    "- 정규분포 근사: 매 시점마다 정규분포 형태를 가짐(정방향 확산과 유사)\n",
    "#### DPM의 loss function\n",
    "VAE와 유사하게 로그 가능도의 하한을 최대화 시킴  \n",
    "두 정규분포 사이의 쿨백-라이블러 발산 계산\n",
    "- 정방향 확산에서 t시점 노이즈를 제거한 평균과 역방향 확산 평균 제곱 오차(MSE)\n",
    "#### VAE와의 차이점\n",
    "잠재변수의 차원이 모두 데이터의 차원과 동일하다. + 여러 단계의 잠재 변수를 가짐  \n",
    "디코더를 모든 시점에서 공유 + 인코더는 학습되지 않음(미리 정해둔 크기의 노이즈를 삽입해 나감)\n",
    "### 디노이징 확산 확률 모델(DDPM; 2020)\n",
    "손실 함수를 간단한 형태로 정리함.  \n",
    "노이즈 예측: U-net 구조  \n",
    "t 시점 주입: 사인 곡선적 포지션 임베딩  \n",
    "\n",
    "#### 생성과정\n",
    "노이즈를 표준정규분포에서 샘플링\n",
    "#### 생성 결과\n",
    "t가 클때: 핵심적인 특징을 담고 있음\n",
    "t가 작을 때: 세부적인 특징을 담고 있음"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
