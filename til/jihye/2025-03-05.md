### 한것
NLP Basic 강의
자연언어처리란?
 ~ 언어학의 사례  
유사도 복습  
딥러닝 복습(~손실함수)

### 배운것

#### Likelihood vs. Probability(P(A))

- 확률 (Probability)
    - 모델(확률 분포)의 파라미터가 주어졌을 때, 데이터가 발생할 확률을 의미합니다.
- 우도 (Likelihood)
    - 주어진 데이터가 특정한 모델의 파라미터를 가질 가능성을 측정하는 값입니다.

$P(X \mid \theta)$ : 확률 함수(probability function) → “주어진 $\theta$에서 데이터 X가 발생할 확률”  
$L(\theta \mid X)$ : 우도 함수(likelihood function) → “관측된 데이터 X를 가장 잘 설명하는 $\theta$는 무엇인가?”

#### Log-Likelihood

Likelihood를 계산하기 위해서는 확률 값을 계속해서 곱해줘야만 한다. 이러한 경우, 확률 값은 0과 1사이의 값들이기 때문에 가능도 값이 너무 작아지는 문제가 발생한다. 따라서 각각의 확률 값에 log를 취해준 다음, 곱하는 과정을 더하는 과정으로 변경해준다.

$\sum_{i=1}^{n} \log P_{\theta}(X = x_i)$

#### Likelihood Function (우도 함수)

우도 함수는 특정한 확률 모델을 가정하고, 주어진 데이터에 대해 해당 모델의 파라미터가 얼마나 적절한지를 평가하는 함수입니다.

예를 들어, 데이터 X = \{x_1, x_2, …, x_n\}가 독립적으로 동일한 확률 분포를 따른다고 가정하면, 우도 함수는 각 데이터의 확률을 곱한 형태로 정의됩니다.

$L(\theta | X) = P(X | \theta) = \prod_{i=1}^{n} P(x_i | \theta)$

즉, 각 데이터가 발생할 확률의 곱으로 표현됩니다.  
(특정한 $\theta$에 대해 우도를 계산하는 함수)

#### Maximum Likelihood Estimation (MLE, 최대우도추정)

최대우도추정(MLE)은 우도 함수를 최대화하는 파라미터 $\theta$를 찾는 방법입니다. 즉, 주어진 데이터가 가장 가능성이 높은 확률 분포의 파라미터를 찾는 과정입니다.

#### 머신러닝에서 우도가 중요한 이유
- 머신러닝 모델 학습: 데이터가 주어졌을 때, 가장 가능성이 높은 모델(혹은 파라미터)을 찾는 데 사용됨.
- 로지스틱 회귀: MLE를 사용해서 최적의 가중치를 찾음.
- 신경망(딥러닝): 손실 함수로 “음의 로그 우도(Negative Log Likelihood, NLL)“를 사용해서 학습 진행.

#### 쿨백-라이블러 발산(Kullback-Leibler divergence, KL divergence)
두 확률 분포 P와 Q 사이의 차이를 측정하는 비대칭적인 거리(metric)입니다. 주로 정보 이론과 머신러닝에서 확률 분포 간 차이를 평가하는 데 사용됩니다.

MLE는 KL 발산을 최소화하는 과정과 연결됩니다.
특히, 모델 Q(x \mid \theta)가 실제 분포 P(x)를 근사할 때,
MLE는 KL 발산을 최소화하는 방향으로 학습됩니다.

$\theta^* = \arg\min_{\theta} D_{KL}(P \parallel Q_{\theta})$

분포를 비교하는 비용 함수로 사용 (예: Variational Autoencoder)

[출처1](https://gbdai.tistory.com/11), 
[출처2](https://huidea.tistory.com/276),
& GPT 