# Fastcampus
## 생성모델의 개요
### 생성모델(Generative models)
데이터는 저차원의 필수적인 정보로부터 생성 가능하다는 가정 하에 분포를 학습하여, 새로운 데이터를 생성하는 모델  
- 데이터는 저차원의 필수적인 정보로 부터 생성 가능하다? = 하나의 image는 수많은 요소로 이루어져 있다.(ex. 어른+안경+남성+미소+...)  


### 확률 분포 추정과 근사
1. 가우시안 혼합 모델 = 정규분포
- 여러 가우시안 분포를 활용해서 실제 데이터와 비슷하게 맞추는 방식
2. 제한된 볼츠만 머신 = 볼츠만 분포
- 인공신경망 기능의 생성모델
- 에너지가 낮을 수록 확률밀도 함수가 커짐.
- 목적함수를 정의하고 최적화 하는 방식
3. 심층 신뢰망(DBN) = 여러 층의 RBM
- 제한된 볼츠만 머신을 쌓은 듯한 모양을 하고 있음. 출력을 입력으로 다시 받는 형식
4. 자기회귀(NADE) = 자기 회귀 기반의 생성모델
- 현재의 픽셀값을 이전의 픽셀값에 의거


### 2014년 이후 딥러닝 기반의 생성모델
1. 변분 오토 인코더 (VAE)
- 흐린 영상 생성의 문제점 = AAE/LVAE로 발전 (분포 개선, 계층 모형) -> WAE, Beta-VAE, VQ-VAE 등으로 다시 발전(학습 개선, 벡터 양자화화)
- 2019년 이후에는 VQ-VAE-2 (고성능, 고해상도 모델 제안), NVAE(Deep VAE) 가 나오면서 점점 발전하기 시작했다.
2. 적대적 생성 신경망(GANs)
- GANs, sGAN 발표 -> Deep Convolution GAN(DCGAN) -> 손실함수, 학습방법 연구 (LSGAN, WGAN)
3. PixelR/CNN
4. Normaliziing Flow
5. 확산 모델(Diffusion Model)
- 열확산 현상 이론 도입
- 매우 느린 생성 속도가 단점이었지만 이를 해결할 수 있는 생성 방식 및 모델 개선을 통해 해결했다.
- 여려 형태의 입력(TEXT, IMAGE, ...)를 받아 IMAGE를 생성할 수 있었다.
- 높은 생성물 의미론 제어 방법 및 개인화 방법등장


### 판별모델
데이터 X가 주어졌을 때, 특성 Y가 나타날 조건부 확률을 직접적으로 반환하는 모델  
= 주어진 데이터를 통해 데이터 사이의 경계를 예측  
#### 판별 모델의 활용
1. 어떤 데이터를 서로 다른 클래스로 분류해 주는 문제에 할용할 수 있음
2. 정상 데이터에 대한 경께를 최대한 좁혀 이를 벗어나는 이상치를 감지하는 문제에도 응용이 가능 = 공장 불량품 찾기
#### 로지스틱 회귀분석
두 그룹의 경계를 곡선으로 FITTING 하기 위해 사용
### 생성모델
데이터 X와 특성 Y의 결합 분포/ Y가 주어질 때 X의 조건부 분포를 추정하는 모델  
주어진 Y가 없는 경우, 데이터 주변(marginal)분포를  추정하는 모델


주어진 데이터를 통해 데이터 분포를 학습함
#### 생성 모델의 어려움
1. 고차원 데이터를 모델링
- 복잡한 모든 특성의 분포를 알아야함. (데이터는 저차원의 정보로 표현 할 수 있다는 가정을 활용함)
2. 평가 지표
- 판별 모델과 달리 생성된 데이터에 대한 정량적 평가가 어려움 (ex. 더 나은 결과물이 무엇인지 평가할 지표가 애매함)


#### 생성모델의 활용
1. 이미지의 품질 개선
2. 맥락에 맞게 이미지 빈 공간 자동 완성
3. 오래된 사진 복구 / 새로운 색감 부여
4. ai 음악 생성


### 생성 모델과 최대 가능도 추정
#### 가능도(likelihood)
모델 파라미터에 의존하는 분포를 따르는 n개의 데이터를 관찰 한 후, 데이터로부터 모델 파라미터를 추정하는 방법 = 가능도를 최대화 하는 파라미터 찾기  
log-likelihood를 사용하는 이유 = 곱셈이 덧셈 형태로 바뀌고, 미분이 쉬워지기 때문 (수식적 해석이 쉬워짐)
#### 최대 가능도 추정법(MLE:Maximum Likelihood Estimation)
가능도를 치대화 하는 파라미터를 찾는 방법  
일반적으로 가능도 함수의 미분을 통해 계산
### 생성 모델의 학습
1. 데이터 분포를 어떻게 모델링 할까? = 모델을 어떻게 학습시켜야 하는가?
- 데이터의 분포와 모델을 가깝게 해야함.
2. 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL-divergence) 최소화
- 직관적으로 분포간 차이/거리 라고 이해하면 쉬움. 하지만 정확한 건 아님
3. 하지만 우리는 데이터의 분포를 모르고 관측치 만 관측할 수 있음.


## 생성모델의 평가지표
### 판별모델의 평가지표
1. 판별 모델은 정답(Ground Truth,GT)이 존재하므로 모델의 출력을 정답과 비교하기 용이하다.
2. 범주형 데이터를 사용하는 경우(분류형)와 연속형 데이터(회귀 분석)를 사용하는 경우로 나눌 수 있다.
- 범주형 데이터의 경우, 정확도/F-Score/ Recall 등의 여러 평가 지표가 존재하며 사용된다.
- 연속형 데이터의 경우, MSE/MAE / R-squared/ 상관계수 등의 여러 평가지표가 존재하며 사용된다.
### 생성모델의 평가가 어려운 이유
1. 비교할 정답이 존재하지 않아 결과를 직접적으로 비교할 대상이 없음
2. 훈련데이터를 정답으로 사용할 경우, 훈련 데이터를 그대로 복제하는 현상이 발생함 (ㄹㅇ 이걸 어캐 한거지?)
3. 주관이 개입 될 여지가 있음 (같은 그림이지만 웃는건지 우는 것인지를 착각할 수 있음)
### 생성모델의 평가지표
#### 어떤 항목들을 평가해야 하는가?
1. 충실도 : 이미지의 품질
2. 다양성 : 이미지의 다양성
#### 평가지표 종류
1. IS(Inception Score)
- Inception v3 모델을 분류기로 이용하여 GAN을 평가하기 위해 고안된 지표
- 예리함과 다양성 두 가지를 주요하게 고려 (IS = Sharpness * Diversity)
- 무질서도(Entropy) : 높을경우 -> 임의의 변수에 대해 예측되는 값이 많음 = 예측이 어려움
- 예리함(Sharpness) : Entropy가 낮을수록 예리해짐
- 다양성(Divergence) : 다양한 유형의 데이터가 분포
- 한계:
    1. 분류기 모델의 훈련 데이터 셋과 다른 데이터를 생성하는 경우 제대로 평가하기 어려움
    2. 계속 같은 데이터를 생성(Mode Collapse), 기울기 기반(Gradient Based) 공격, 리플레이(Replay) 공격을 통해 점수 조작이 가능
2. FID(Frechet Inception Distanch)
- 낮을 수록 좋음
- 생성된 데이터의 특징 벡터를 이용하여 훈련 데이터와의 거리를 계산
- 한계
    1. Fidelity와 Diversity를 각각 평가할 수 없음. = 어느쪽이 강조되었는지 혹은 균형 잡힌 모델인지 알 수 없음
3. 개선된 정밀도, 재현율 (Improved Precision & Recoall)
- 정밀도(Precision) : Positive 예측한 것 중 실제로 Positive인 경우 = TP/(TP+FP)
- 재현율(Recall) : 실제 positive 한 것 들 중에서 옳바르게 예측한 경우 = TP/(TP+FN)
- 한계: 이상치에 민감, 실제 데이터와 생성된 데이터의 분포가 동일하더라도 샘플링에 따라 점수가 낮을 수 있음


4. 조건부 정확도 (Conditional Accuracy)
- 레이블이 주어졌을 때, 데이터의 분포를 학습 = 특저조건을 만족하는데이터를 생성 가능
5. LPIPS(Learned Perceptual Image Patch Similarity)
- 모델 특징 비교를 통한 영상간 유사도 측정 = 우리가 어떻게 두 이미지가 비슷하다고 느끼는가
- 원본 영상과 유사도가 낮다 = 더 다양하게 생성했다로 해석
6. CLIP-Score
- Text-image 관계를 학습한 CLIP을 특징 추출기로 활용해서 유사도를 측정함함
## 오토 인코더와 변분 오토 인코더
### 오토인코더
입력 데이터의 패턴을 학습하여 데이터를 재건하는 모델(비선형 차원 축소기법으로 활용 가능)
1. 인코더: 데이터를 저차원 잠재 표현으로 요약
2. 디코더: 저차원 잠재 표현으로 부터 데이터를 재구성
3. 손실 함수 : 잠재 표현으로부터 복구한 데이터와 입력 데이터의 MSE
### 디노이징 오토 인코더
입력 데이터에 random noise를 주입하거나 Dropout layer를 적용  
노이즈가 없는 원래 데이터로 재구성
#### 원리
안개 속에서 멀리 있는 물체를 구별할 때, 데이터의 특성들을 더욱 정확히 학습함(가려져도 구별되는 특별한 특징을 학습함)  
노이즈에 강건한 잠재 표현 (미세하게 변형된 데이터도 같은 잠재 벡터로 표현 되도록)


### 오토 인코더 활용
학습한 오토 인코더의 인코더 부분을 특징 추출기로 활용  
잠재 벡터로부터 분류, 클러스터링 문제 해결  


### 변분 오토 인코더(VAE)의 구조
1. 데이터는 저차원의 잠재 변수로부터 생성된다는 가정을 기반에 두고 있음.
2. 잠재 벡터의 분포는 표준정규분포를 따르게 만든다.


### 변분 오토 인코더의 학습
잠재 변수가 표중정규분포를 따른다고 가정(사전분포->p(z))  
각 특징을 확률분포로 정의, 이로부터 샘플링을 수행함.  


#### ELBO(Evidence of Lower BOund)
현재 모델이 우리가 가진 현상을 얼마나 잘 설명하는가 = 가능도(likelihood)  
직접 계산이 어려우니, 간접적으로 계산하여 최대화함.
가능도는 계산이 안되지만 ELBO는 계산이 가능함. 따라서 ELBO를 최대화  


#### VAE의 loss function
재매개변수화 방법 이용  


#### 변분 오토 인코더의 활용
1. 잠재 벡터를 표준정규분포에서 샘플링, 디코더의 분포로붵 새로운 데이터를 생성
2. 대표적인 특징은 잘 생성하지만 뿌연듯한 느낌이 많이 듦.
3. 의미있는 잠재 표현을 학습할 수 있음. 이는 발전의 여지를 ㄴ남길 수 있다는 점에서 큰 장점임.
#### 장점 & 단점
1. 장점 : 데이터를 요약하는 유용한 잠재 표현을 찾을 수 있음
2. 단점 : 가능도가 아닌 가능도의 하한을 최대화 하기 때문에 흐릿한 이미지를 생성하게 된다.

### 벡터 양자화 변분 오토 인코더(VQVAE)
유한한 잠재 표현형: 실제 이미지나 텍스트는 유한한 특성으로 표현할 수 있음.  
이산 잠재 변수 (Discrete): 범주 K개의 D차원 임베딩 벡터  

## 적대적 생성 신경망 (GANs)
### GANs
Generative, Adversarial Netsorks  
적대적으로 학습하는 신경망들로 구성되며, 생성 모델로써 활용함  
최적화가 어렵고 두개의 신경망이 있으므로 학습에 오래걸림  
생성된 데이터의 다양성이 낮을 수 있음.
### VAE vs GANs
1. 생성방식
- VAE의 생성 방식 : 입력 분포를 근사하는 과정에서 규제을 주며 데이터를 생성
- GANs의 생성 방식 : 생성된 데이터오 실제 데이터를 판별하고 속이는 과정을 거치며 생성 모델을 개선
2. 생성 결과
- VAE의 결과물은 상대적으로 흐릿하고, 입력데이터와 유사한 형태로 생성
- GANs의 결과물은 상대적으로 뚜렷하고, 입력데이터와 다른 형태의 데이터를 생성
#### GANs 구조
1. 데이터를 생성하는 생성모델과 데이터의 진위를 구별하는 판별모델(Discriminator)로 구성
- 판별 모델: 생성된 데이터를 입력으로 받아 실제 데이터인지 생성된 데이터인지를 출력
#### GANs 목적
1. 생성 모델의 분포와 판별 모델의 예측을 지속적으로 갱신하면서 학습됨.
- 임의의 초기 분포로부터 생성 모델이 데이터를 생성
- 판별 모델이 분류; 판별 모델 갱신
- 갱신된 판별 모델을 고정; 생성 모델 갱신
- 반복 과정을 거쳐 생성 모델은 판별 모델이 구별할 수 없는 수준의 데이 터를 생성

### 조건부 생성 모델
생성 모델: 임의의 잠재 벡터로부터 데이터를 생성
데이터를 잘 생성하나 그들의 의미는 제어할 수 없음

#### 이미지 대 이미지 변환: 전통적 접근
이미지 변환의 대표적인 예시: 색상 변환, 잔밤 변환, 스케치 채색 등  
조건부 GANs이전에는 각 태스크별 모델과 손실 함수를 각각 정의해야 했음  
#### pix2pix
이미지 쌍이 있는 조건부 생성 모델 기반의 이미지 대 이미지 변환 프레임 워크를 제안
- 이미지 특성별로 회귀 모형을 만드는 것이 아닌, 생성 모델이 변환된 이미지를 생성하자

데이터가 반드시 쌍으로 존재해야 하기에, 데이터를 확보하는 것이 어려움
ex)같은 위치의 다른 계절, 같은 위치와 같은 자세의 얼룩말과 말 등...

#### cycleGAN
상호 변환이 가능한 것; 한국어->영어 변환이 가능하다면 영어->한국어 변환도 가능해야함  
입력 이미지로 복원 가능한 정도까지만 이미지를 변환하도록 하여 원본 손실을 최소화  

하나의 입력, 다양한 출력- 하나의 영상이 다른 도메인에서 여러 양상으로 그려질 수 있음.

#### StarGAN
3개 이상의 도메인 간 변환을 수행함
#### GigaGAN
다른 생성모델처럼 모델의 규모와 데이터를 매우 크게 만들어 학습, 텍스트 기반으로 고해상도 이미지를 생성함
저화질 생성 이후 고화질 변환 모델로 화질 개선 작업 수행
- 기존 text2image의 패러다임을 따름
## 확산 모델 (Difusion model)
### 확산 확률 모델
최근 활발히 연구되고 있는 모델  
픽셀 값이 섞이고 번져가다가 마지막에는 균일한 농도의 noise가 되는 현상을 이용   
#### DPM - 확률
확산 현상을 시간에 따라 확률적 모델링  
마르코프체인: 미래는 과거가 아닌 현재에만 의존한다.
#### DPM - 구조
정방향 확산: 데이터 -> 노이즈 (고정)
- 이미지 파괴과정 = T = 1000 시점 동안 노이즈를 주입
역반향 확산: 노이즈 -> 데이터 (학습)
- 이미지 생성과정 = 노이즈를 제거하는 과정은 계산 불가
- 정규분포 근사: 매 시점마다 정규분포 형태를 가짐(정방향 확산과 유사)
#### DPM의 loss function
VAE와 유사하게 로그 가능도의 하한을 최대화 시킴  
두 정규분포 사이의 쿨백-라이블러 발산 계산
- 정방향 확산에서 t시점 노이즈를 제거한 평균과 역방향 확산 평균 제곱 오차(MSE)
#### VAE와의 차이점
잠재변수의 차원이 모두 데이터의 차원과 동일하다. + 여러 단계의 잠재 변수를 가짐  
디코더를 모든 시점에서 공유 + 인코더는 학습되지 않음(미리 정해둔 크기의 노이즈를 삽입해 나감)
### 디노이징 확산 확률 모델(DDPM; 2020)
손실 함수를 간단한 형태로 정리함.  
노이즈 예측: U-net 구조  
t 시점 주입: 사인 곡선적 포지션 임베딩  
- 한계점
    1. 느린 생성과정: 5만개의 32*32크기 이미지 생성을 위해 20시간이 필요하다
    2. 조건부 생성 불가: 품질-다양성 조절 불가능
#### 생성과정
노이즈를 표준정규분포에서 샘플링
#### 생성 결과
t가 클때: 핵심적인 특징을 담고 있음
t가 작을 때: 세부적인 특징을 담고 있음


#### DDIM
T = 1000 보다 적은 시점을 거쳐서 데이터를 생성할 수 있을까?  
DDPM과 같은 loss function을 가지며 T = 1000 시점에 대해 동일하게 학습 한다.  
마르코프 체인(미래는 과거가 아닌 현재에만 의존한다.)을 가정하지 않는다.
따라서 차근차근 앞으로 나아가는 것이 아니라 2칸, 혹은 3칸씩 넘어서 sampling이 가능하다.  
노이즈 공간에서 내삽(Interplation)이 가능하다  

#### Denoising Diffusion GANs (2022)
DDPM의 핵심 = 노이즈가 작을 때는 정규분포로 근사 가능  
시점이 0에 가까울수록 디노이징 분포가 정규분포보다 폭잡해짐  
적은 시점을 사용하기 위해 조건부 GAN을 활용하여 복잡한 디노이징 분포를 학습  
적대적 학습으로 t시점의 데이터 xt가 주어졌을 때, t-1시점의 데이터의 분포학습

#### Progressive Distillation (2022)
학습된 확산 확률 모델로부터 시점을 절반으로 줄이는 경량화 된 모델을 반복적으로 학습  
이웃한 2개의 역방향 확산 과정을 하나로 합침  

#### Consistency Model and Distillation (2023)
학습시 모든 Time Step에 동일한 결과를 내도록 학습을 진행함
- 이를 Pretrained Diffusion Model에 적용, Distillation 진행 가능  

#### Latent Consistency
1 step to 8 steps

### 조건부 생성
#### 조건부 DPM
정방향 확산은 고정  
역방향 확산에서 조건 추가  

1. Guided Diffusion(2021)
- t 시점 데이터 x로 부터 클래스 y를 에측하는 분류기를 사전학습
- 생성 과정에서 분류기의 그래디언트를 따라 이동
- 분류기 그래디언트의 스케일이 중요 -> 얼마나 해당 클래스의 정보를 주입할 것인가
- 스케일을 조절하면 클래스를 유지하도록 생성 가능하지만 분류기를 추가 학습해야 하는 단점이 있음

2. Classifier-free Diffusion Guidance (2021)
- 분류기를 베이즈 정리를 활용하여 대체함
- 확산확률 모델과 조건부 확산 확률 모델을 함께 학습함(학습할 때 랜덤하게 클래스를 버림)
- 생성할 때 두 모델에서 예측한 노이즈의 가중합 계산

### 고해상도 이미지 생성
많은 양의 계산 자원을 필요로 함.  
문제는 알아차리기 어려운 부분에 모델이 큰 힘을 쏟는 것

따라서 기존의 픽셀 공간에서 잠재 공간으로 이동시킴으로 이득을 본다.
- 고차원 이미지 공간에서 연산을 반복하는 대신 이미지 정보를 유지한 채로 차원을 축소시킬 수 있다면 게산 복잡도를 감소 시킬 수 있다.  

영상 생성은 인지적 압축 과정과 의미적 압축으로 대략적 구분이 가능하다.
- 인지적 압축: 과도한 세부 사항을 제거하며 핵심적인 특징을 잠재표현으로 요약
- 의미적 압축: 데이터의 의미적, 구조적 특징을 학습

확산 모델의 정방향, 역방향 확산 과정을 이미지 공간이 아닌 오토 인코더의 잠재공간에서 진행
- 재건된 이미지와 실제 이미지를 패치 단위로 판별하는 적대적 오토 인코더 (Autoencoder+GAN)활용  

### 잠재확산 모델
실제 이미지의 고차원 공간이 아닌 잠재공간에서 노이즈 연산을 반복하도록 설계  
확산 모델에서 주요한 연산들이 모두 잠재 공간에서 이루어지므로 훨씬 더 효율적인 공간에서 훈련 가능
- 기존 확산 모델보다 계산, 시간 자원 모두 효율적  

잠재확산 모델을 훈련하기 위해서는 2가지 학습 단계가 순차적으로 이루어져야 함.  
1. 좋은 잠재 공간을 얻기 위해 변분 오토 인코더를 학습 하는 과정
- 사전 훈련: 벡터 양자화 변분 오토 인코더: 재건된 이미지를 가짜 이미지로 두어 실제 이미지와 판별하는 과정 포함
2. 얻어진 잠재 공간으로 부터 확산 모델을 학습하는 과정
- 확산 모델과 동일하게 노이즈 예측 모델 훈련
- 노이즈 주입의 대상이 입력 이미지가 아닌 잠재표현인 점이 기존 확산 모델과의 차이

결과적으로 기존 확산모델보다 계산 복잡도가 감소했음에도 고해상도 이미지를 잘 생성해냄  
잠재공간의 연산이 노이즈 감소와 의미에 집중하는 역할을 충실히 수행했다고 볼 수 있음  

### 조건부 생성
#### 잠재 확산 모델을 이용한 Text-to Image
잠재 확산 모델은 확산 모델과 마찬가지로 다양한 조건부 생성이 가능
- Text2Image, 고해상도 이미징, 인페이팅 등  
잠재 확산 모델은 텍스트 인코딩을 위해 CLIP의 텍스트 인코더를 활용
- CLIP? : 텍스트 입력이 추가되는 경우, 텍스트 인코더를 사전 훈련하는 단게가 필요. 텍스트 이미지 쌍에 대한 이해가 높은 모델. 

확산모델과의 차이: 텍스트 정보와 노이즈화된 잠재 표현의 관계성 학습을 위해 Cross-attention을 추가
- Cross-attention의 대상이 텍스트-이미지가 아니라 텍스트-잠재표현임을 주목

## 확산 모델의 개인화
### T2I 모델의 문제점
1. text 설명만으로 정확히 원하는 대상을 얻어내기 어려움
개인화 = 우리가 원하는 대상에 관한 사진이 일부 있을 때 피사체에 대한 새로운 이미지를 텍스트로부터 생성하는 방법  
### 텍스트 반전(text Inversion)
특정 개념이나 스타일을 사용자가 정의하여 모델이 학습하도록 하는 기술.  
기존 모델을 유지하면서 개념을 추가하는 가벼운 방법
추가적인 사전 훈련 없이, 기존 모델을 활용하여 특정 단어냐 개념을 강화하는 방법
- 사용자 맞춤 캐릭터 학습
- 특정 미술 스타일 적용
- 특정 오브젝트 생성

### DreamBooth
사전학습된 T2I확산 모델을 특정 개념에 맞게 미세 조정(Fine tuning)  
새로운 개념을 모델 자체에 추가하는 강력한 방법
- 단점: 언어 드리프트 (대상과 동일한 클래스의 이미지를 생성하는 방법을 천천히 잊어버림)

### 로라(Low-Rank Adaptation)
자연어 처리 모델의 파인튜닝에 활용하는 기법인 LoRA 활용  
Text Encoder 또는 Unet의 Cross-Attention layer에 LoRA 기법을 적용하여 파인튜닝  
기존 가중치는 유지하고 가중치 변화량을 학습 -> 기존 학습결과를 잊지 않는 효과
가중치 변화량을 행렬 2개의 곱으로 분해 -> 학습 파라미터 수가 대폭 감소  
- 파인튜닝의 경우 아주 작은 파라미터를 업데이트 하는 것만으로 좋은 성능을 보임  
DreamBooth와 함께 사용 가능하다.

| 항목         | DreamBooth                        | 텍스트 반전 (Text Inversion)          | LoRA (Low-Rank Adaptation)         |
|------------|--------------------------------|--------------------------------|--------------------------------|
| 학습 방식   | 모델 자체를 미세 조정(Fine-tuning) | 기존 모델의 텍스트 임베딩을 업데이트 | 모델 가중치의 일부만 학습하여 조정  |
| 데이터 필요량 | 3~10장 정도                        | 3~5장 정도                         | 10~20장 정도                        |
| 학습 시간   | 상대적으로 오래 걸림                 | 더 빠르게 학습 가능         | DreamBooth보다 빠르지만 Text Inversion보다는 느림 |
| 적용 방식   | 모델을 다시 저장해야 함              | 기존 모델을 그대로 사용 가능         | LoRA 가중치를 추가로 로드하여 적용  |
| 개념 일반화 | 새로운 개념을 모델 내부에 저장       | 새로운 개념을 특정 텍스트 토큰에 매핑 | 특정 개념을 가볍게 학습하여 추가 가능 |
| 장점        | 강력한 개념 학습 및 일반화 가능      | 가벼운 방식으로 빠르게 개념 추가 가능 | 모델 전체를 조정하지 않고도 새로운 개념 추가 가능 |
| 단점        | 연산 비용이 크고 모델 저장 필요      | 개념 일반화가 어렵고 프롬프트에 의존 | 추가 가중치를 불러와야 하며, 일부 제한적 학습 |

### ControlNet
다양한 structural input을 조건으로 주기 위한 방법  
추가적인 layer를 학습해 U-Net은 유지하고 차이를 추가하는 방법  